{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMA1bu9I8gbzyamh+p8cePU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.\n","   - Simple Linear Regression (SLR) is a statistical method used to study the relationship between two variables — one independent variable (X) and one dependent variable (Y).\n","It helps us predict the value of Y based on the value of X.\n","\n","   \n","   In SLR, we assume that there is a linear (straight-line) relationship between X and Y, which can be represented by the equation:\n","\n","\n","    Y=a+bX+e\n","\n","Where:\n","\n","Y = Dependent variable (the outcome we want to predict)\n","\n","X = Independent variable (the predictor or input variable)\n","\n","a = Intercept (the value of Y when X = 0)\n","\n","b = Slope (shows how much Y changes for a one-unit change in X)\n","\n","e = Error term (difference between the actual and predicted values)\n","\n","\n","Purpose of Simple Linear Regression:\n","\n","Prediction:\n","\n","It helps predict the value of one variable based on another.\n","Example: Predicting sales (Y) based on advertising spend (X).\n","\n","Understanding Relationships:\n","\n","It helps identify and measure the strength and direction of the relationship between two variables (whether positive or negative).\n","Trend Analysis:\n","It is used to analyze trends and patterns in data — for example, predicting future demand based on past data.\n","\n","Decision Making:\n","\n","Businesses and researchers use SLR to make data-driven decisions by understanding how one factor affects another.\n","\n","Example:\n","\n","Suppose we want to predict a student’s exam score (Y) based on the number of study hours (X).\n","After collecting data, we might find the regression equation as:\n","\n","\n","\n","Exam Score=40+5×(Study Hours)\n","\n","This means:\n","\n","  - The base score is 40 (intercept),\n","\n","  - For each extra study hour, the score increases by 5 points (slope)."],"metadata":{"id":"6O_lWwtyH5mb"}},{"cell_type":"markdown","source":["\n","\n","### **Question 2: What are the key assumptions of Simple Linear Regression (SLR)?**\n","\n","**Answer:**\n","\n","Simple Linear Regression (SLR) is based on certain **assumptions** to ensure that the results are accurate and reliable.\n","If these assumptions are violated, the predictions and conclusions from the model may not be correct.\n","\n","Below are the **key assumptions of Simple Linear Regression**:\n","\n","\n","### **1. Linearity**\n","\n","There must be a **linear relationship** between the independent variable (X) and the dependent variable (Y).\n","This means the change in Y is proportional to the change in X.\n","\n","* Example: If study hours increase, marks should increase (or decrease) in a straight-line pattern.\n","\n","\n","\n","### **2. Independence of Errors**\n","\n","The **residuals (errors)** — the differences between actual and predicted values — should be **independent** of each other.\n","\n","* This means one observation’s error should not affect another’s.\n","* Example: In time-series data, today’s error should not depend on yesterday’s error.\n","\n","\n","\n","### **3. Homoscedasticity (Constant Variance of Errors)**\n","\n","The **variance of errors** should remain **constant** across all levels of the independent variable.\n","\n","* In simple terms, the spread of residuals should be roughly the same for all X values.\n","* If the variance changes (gets wider or narrower), it indicates **heteroscedasticity**, which violates this assumption.\n","\n","\n","### **4. Normality of Errors**\n","\n","The **residuals (errors)** should be **normally distributed** (bell-shaped curve).\n","\n","* This is important for making valid predictions and hypothesis testing.\n","* You can check this by using a histogram or Q-Q plot of residuals.\n","\n","\n","\n","### **5. No Multicollinearity (Not applicable in SLR but important generally)**\n","\n","In **Simple Linear Regression**, there is only **one independent variable**, so multicollinearity doesn’t occur.\n","However, this assumption becomes important in **Multiple Linear Regression**, where independent variables should not be highly correlated with each other.\n","\n","\n","\n","### **6. No Significant Outliers**\n","\n","The dataset should **not contain extreme values (outliers)** that can distort the regression line.\n","Outliers can pull the line away from the true relationship between X and Y.\n","\n","\n","**In summary:**\n","For Simple Linear Regression to give valid and trustworthy results, the data should follow these assumptions:\n","**Linearity, Independence, Homoscedasticity, Normality, and No Outliers.**\n","\n","\n"],"metadata":{"id":"6r_0HgE2JGEb"}},{"cell_type":"markdown","source":["\n","\n","### **Question 3: Write the mathematical equation for a Simple Linear Regression model and explain each term.**\n","\n","**Answer:**\n","\n","The **mathematical equation** for a **Simple Linear Regression (SLR)** model is:\n","\n","[\n","Y = a + bX + e\n","]\n","\n","\n","\n","### **Explanation of Each Term:**\n","\n","| **Term** | **Meaning**           | **Explanation**                                                                                                                                                       |\n","| -------- | --------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n","| **Y**    | Dependent Variable    | This is the variable we want to **predict or explain**. It depends on the value of X.                                                                                 |\n","| **X**    | Independent Variable  | This is the variable used to **predict** the value of Y. It is also called the predictor or explanatory variable.                                                     |\n","| **a**    | Intercept             | It is the value of Y when X = 0. It represents the point where the regression line crosses the Y-axis.                                                                |\n","| **b**    | Slope                 | It shows how much Y **changes for every one-unit change in X**. A positive slope means Y increases as X increases; a negative slope means Y decreases as X increases. |\n","| **e**    | Error Term (Residual) | It represents the **difference between the actual value and the predicted value** of Y. It captures random factors not explained by X.                                |\n","\n","\n","\n","### **Alternate Form (Predicted Value):**\n","\n","The predicted value of Y (often written as **Ŷ**) is given by:\n","\n","[\n","\\hat{Y} = a + bX\n","]\n","\n","Here, **Ŷ** (Y-hat) represents the **estimated** value of Y from the regression line (without including error).\n","\n","\n","### **Example:**\n","\n","Suppose we are predicting a student’s exam score (Y) based on study hours (X).\n","After analyzing data, we get:\n","\n","[\n","Y = 40 + 5X\n","]\n","\n","This means:\n","\n","* The intercept (**a = 40**) → if a student studies 0 hours, the predicted score is 40.\n","* The slope (**b = 5**) → for each additional hour of study, the exam score increases by 5 marks.\n","\n","\n"," **In summary:**\n","The Simple Linear Regression equation ( Y = a + bX + e ) describes the straight-line relationship between an independent variable (X) and a dependent variable (Y), where **a** and **b** determine the line, and **e** accounts for random errors.\n","\n","\n"],"metadata":{"id":"kH6dcdsOJerh"}},{"cell_type":"markdown","source":["\n","\n","### **Question 4: Provide a real-world example where Simple Linear Regression can be applied.**\n","\n","**Answer:**\n","\n","**Simple Linear Regression (SLR)** can be applied in many real-life situations where we want to **predict one variable** based on **another related variable**.\n","\n","\n","\n","### **Example: Predicting House Prices Based on Size**\n","\n","**Situation:**\n","A real estate company wants to **predict the price of a house (Y)** based on its **size in square feet (X)**.\n","\n","\n","\n","### **How It Works:**\n","\n","* **Dependent Variable (Y):** House Price (in ₹ or $)\n","* **Independent Variable (X):** House Size (in square feet)\n","\n","By collecting data from several houses — their sizes and corresponding prices — the company can fit a **simple linear regression model**.\n","\n","The model might look like:\n","\n","[\n","\\text{House Price} = 50,000 + 3,000 \\times (\\text{House Size})\n","]\n","\n","\n","### **Interpretation:**\n","\n","* **Intercept (50,000):**\n","  This represents the **base price** of a house, even if its size is zero (a theoretical starting point).\n","\n","* **Slope (3,000):**\n","  For every **additional square foot**, the house price **increases by ₹3,000** on average.\n","\n","So, if a house is 1,000 sq. ft., the predicted price would be:\n","[\n","50,000 + 3,000(1000) = ₹30,50,000\n","]\n","\n","\n","\n","### **Purpose of Using SLR Here:**\n","\n","* To **estimate or predict** property prices for new houses.\n","* To **understand the relationship** between house size and price.\n","* To **help buyers and sellers** make informed decisions.\n","\n","\n","\n","✅ **Other Real-World Examples:**\n","\n","* Predicting **sales** based on **advertising spend**.\n","* Predicting **student marks** based on **study hours**.\n","* Predicting **fuel consumption** based on **vehicle speed**.\n","* Predicting **crop yield** based on **rainfall**.\n","\n","\n","\n","**In summary:**\n","Simple Linear Regression is useful whenever we want to model and predict the relationship between **one independent variable (X)** and **one dependent variable (Y)** in a **linear (straight-line)** way.\n","\n"],"metadata":{"id":"tldvl56EKDIO"}},{"cell_type":"markdown","source":["\n","\n","### **Question 5: What is the method of least squares in linear regression?**\n","\n","**Answer:**\n","\n","The **method of least squares** is a mathematical technique used in **linear regression** to find the **best-fitting line** through a set of data points.\n","It helps determine the values of the **intercept (a)** and **slope (b)** in the regression equation:\n","\n","[\n","Y = a + bX + e\n","]\n","\n","\n","\n","### **Purpose:**\n","\n","The goal of the least squares method is to make the **difference between the actual values** and the **predicted values** as **small as possible**.\n","\n","These differences are called **errors** or **residuals**.\n","\n","\n","\n","### **Concept:**\n","\n","For each data point ((X_i, Y_i)):\n","\n","* The actual value is ( Y_i )\n","* The predicted value from the regression line is ( \\hat{Y_i} = a + bX_i )\n","* The **residual** (error) is:\n","  [\n","  e_i = Y_i - \\hat{Y_i}\n","  ]\n","\n","The **method of least squares** minimizes the **sum of the squares of these residuals**, expressed as:\n","\n","[\n","\\text{Minimize } \\sum (Y_i - \\hat{Y_i})^2\n","]\n","\n","That’s why it’s called the **“least squares”** method — because it minimizes the squared errors.\n","\n","\n","\n","### **Why Squares Are Used:**\n","\n","* Squaring ensures that positive and negative errors do not cancel out.\n","* It gives more weight to larger errors, helping the line fit the data more accurately.\n","\n","\n","\n","### **Result:**\n","\n","By applying this method, we get the **best-fit line** — the line that passes as close as possible to all data points and represents the overall trend in the data.\n","\n","The calculated values of:\n","[\n","b = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2}\n","]\n","[\n","a = \\bar{Y} - b\\bar{X}\n","]\n","give the slope and intercept of the regression line.\n","\n","\n","\n","### **Example:**\n","\n","If a company wants to predict **sales (Y)** from **advertising spend (X)**, the least squares method helps find the line that best describes how sales change with advertising.\n","\n","\n"," **In summary:**\n","The **method of least squares** finds the regression line that **minimizes the total squared differences** between actual and predicted values, ensuring the best possible fit to the data.\n","\n"],"metadata":{"id":"06kc2cIDKdA7"}},{"cell_type":"markdown","source":["\n","\n","### **Question 6: What is Logistic Regression? How does it differ from Linear Regression?**\n","\n","**Answer:**\n","\n","#### **1. What is Logistic Regression?**\n","\n","**Logistic Regression** is a **statistical method** used to **predict categorical outcomes**, especially when the dependent variable has **two possible outcomes** (e.g., Yes/No, 0/1, Pass/Fail).\n","\n","It is commonly used for **classification problems** rather than prediction of continuous values.\n","\n","Unlike Linear Regression, which gives a continuous output, **Logistic Regression predicts probabilities** of outcomes, and then classifies them into categories.\n","\n","\n","\n","#### **2. Logistic Regression Equation:**\n","\n","The logistic regression model predicts the **probability (p)** that the dependent variable equals 1 (the “yes” or “success” category):\n","\n","[\n","p = \\frac{1}{1 + e^{-(a + bX)}}\n","]\n","\n","Where:\n","\n","* **p** = Probability of the event occurring (Y = 1)\n","* **a** = Intercept\n","* **b** = Slope (regression coefficient)\n","* **X** = Independent variable\n","* **e** = Base of the natural logarithm (~2.718)\n","\n","This equation ensures that the predicted value of **p** is always between **0 and 1**.\n","\n","\n","#### **3. Purpose of Logistic Regression:**\n","\n","* To **classify** data into categories.\n","* To **estimate probabilities** of binary outcomes.\n","* To **understand relationships** between a categorical dependent variable and one or more independent variables.\n","\n","\n","\n","#### **4. Difference Between Linear Regression and Logistic Regression:**\n","\n","| **Basis**              | **Linear Regression**                                         | **Logistic Regression**                                |\n","| ---------------------- | ------------------------------------------------------------- | ------------------------------------------------------ |\n","| **Type of Output**     | Predicts a **continuous numeric value** (e.g., income, marks) | Predicts a **categorical outcome** (e.g., yes/no, 0/1) |\n","| **Dependent Variable** | Continuous                                                    | Categorical (mostly binary)                            |\n","| **Equation Form**      | ( Y = a + bX )                                                | ( p = \\frac{1}{1 + e^{-(a + bX)}} )                    |\n","| **Range of Output**    | Can take any real value (−∞ to +∞)                            | Always between 0 and 1 (as probability)                |\n","| **Purpose**            | Used for **prediction and estimation**                        | Used for **classification and probability estimation** |\n","| **Example**            | Predicting house prices based on size                         | Predicting if a customer will buy a product (Yes/No)   |\n","\n","\n","\n","#### **Example:**\n","\n","A bank wants to predict whether a customer will **default on a loan (Yes = 1, No = 0)** based on income.\n","\n","* **Dependent variable (Y):** Loan Default (0 or 1)\n","* **Independent variable (X):** Income\n","\n","The logistic regression model gives the **probability** that a person will default, helping the bank make lending decisions.\n","\n","\n","**In summary:**\n","**Logistic Regression** is used for **classification** problems where the output is categorical, while **Linear Regression** is used for **prediction** of continuous values.\n","Logistic Regression models the **probability** of an event using a **sigmoid (S-shaped) curve** instead of a straight line.\n","\n"],"metadata":{"id":"jUYViw5DKxuB"}},{"cell_type":"markdown","source":["\n","### **Question 7: Name and briefly describe three common evaluation metrics for regression models.**\n","\n","**Answer:**\n","\n","When we build a **regression model**, it’s important to check **how well the model predicts** the actual values.\n","To measure its performance, we use **evaluation metrics** that compare the **predicted values (Ŷ)** to the **actual values (Y)**.\n","\n","Here are **three common evaluation metrics** used for regression models:\n","\n","\n","\n","### **1. Mean Absolute Error (MAE)**\n","\n","**Definition:**\n","MAE measures the **average of the absolute differences** between actual and predicted values.\n","\n","[\n","\\text{MAE} = \\frac{1}{n} \\sum |Y_i - \\hat{Y_i}|\n","]\n","\n","**Meaning:**\n","It tells us how far the predictions are, on average, from the actual values — without considering the direction of the error.\n","\n","**Example:**\n","If MAE = 5, it means the model’s predictions are off by 5 units on average.\n","\n","✅ **Lower MAE = Better model performance**\n","\n","\n","\n","### **2. Mean Squared Error (MSE)**\n","\n","**Definition:**\n","MSE is the **average of the squared differences** between actual and predicted values.\n","\n","[\n","\\text{MSE} = \\frac{1}{n} \\sum (Y_i - \\hat{Y_i})^2\n","]\n","\n","**Meaning:**\n","It penalizes larger errors more strongly because errors are **squared**.\n","It’s useful when you want to heavily penalize big mistakes.\n","\n","**Example:**\n","If MSE = 16, it means the average squared error is 16.\n","\n","✅ **Lower MSE = More accurate model**\n","\n","\n","\n","### **3. R-squared (Coefficient of Determination)**\n","\n","**Definition:**\n","R-squared measures how well the independent variable(s) explain the variation in the dependent variable.\n","\n","[\n","R^2 = 1 - \\frac{\\text{SS}*{\\text{res}}}{\\text{SS}*{\\text{tot}}}\n","]\n","\n","Where:\n","\n","* ( \\text{SS}_{\\text{res}} ) = Sum of squared residuals (errors)\n","* ( \\text{SS}_{\\text{tot}} ) = Total sum of squares\n","\n","**Meaning:**\n","It shows the **percentage of variation** in Y that is explained by the model.\n","\n","**Example:**\n","If ( R^2 = 0.85 ), it means **85% of the variation** in Y is explained by the regression model.\n","\n","✅ **Higher R² = Better model fit**\n","\n","\n","\n","### **Summary Table:**\n","\n","| **Metric** | **Formula**                                     | **Ideal Value** | **Interpretation**      |             |                    |\n","| ---------- | ----------------------------------------------- | --------------- | ----------------------- | ----------- | ------------------ |\n","| **MAE**    | ( \\frac{1}{n} \\sum                              | Y_i - \\hat{Y_i} | )                       | Closer to 0 | Average error size |\n","| **MSE**    | ( \\frac{1}{n} \\sum (Y_i - \\hat{Y_i})^2 )        | Closer to 0     | Penalizes large errors  |             |                    |\n","| **R²**     | ( 1 - \\frac{\\text{SS}*{res}}{\\text{SS}*{tot}} ) | Closer to 1     | Explains variation in Y |             |                    |\n","\n","\n","\n","**In summary:**\n","MAE and MSE measure **how far predictions are from actual values**, while R² tells us **how well the model explains the data**.\n","Together, they help evaluate the **accuracy and reliability** of a regression model.\n","\n"],"metadata":{"id":"7HzOplx6LGuW"}},{"cell_type":"markdown","source":["\n","\n","### **Question 8: What is the purpose of the R-squared metric in regression analysis?**\n","\n","**Answer:**\n","\n","The **R-squared (R²)** metric, also known as the **Coefficient of Determination**, is used to measure **how well a regression model explains the variation** in the dependent variable (Y).\n","\n","In other words, it tells us **how well the data fit the regression line**.\n","\n","\n","\n","### **1. Definition:**\n","\n","R-squared represents the **proportion (percentage)** of the total variation in the dependent variable that is **explained by the independent variable(s)** in the model.\n","\n","[\n","R^2 = 1 - \\frac{\\text{SS}*{res}}{\\text{SS}*{tot}}\n","]\n","\n","Where:\n","\n","* ( \\text{SS}_{res} ) = Sum of squared residuals (errors)\n","* ( \\text{SS}_{tot} ) = Total sum of squares (total variation in Y)\n","\n","\n","\n","### **2. Interpretation:**\n","\n","* ( R^2 = 0 ) → The model explains **none** of the variation in Y.\n","* ( R^2 = 1 ) → The model explains **all** the variation perfectly.\n","* ( R^2 = 0.75 ) → The model explains **75% of the variation** in Y, while 25% remains unexplained (due to random error or other factors).\n","\n","\n","\n","### **3. Purpose of R-squared:**\n","\n","1. **Measure of Fit:**\n","   It shows how well the regression line fits the data points.\n","\n","2. **Model Evaluation:**\n","   It helps assess whether adding more variables improves the model’s performance.\n","\n","3. **Explained Variance:**\n","   It indicates how much of the dependent variable’s behavior can be predicted by the independent variable(s).\n","\n","4. **Comparison Tool:**\n","   It allows us to compare different regression models — a higher R² usually means a better fit (if other conditions remain the same).\n","\n","\n","\n","### **4. Example:**\n","\n","If a regression model predicting **house price (Y)** from **house size (X)** gives ( R^2 = 0.85 ),\n","it means **85% of the variation** in house prices can be explained by house size, and **15%** is due to other factors.\n","\n","\n","\n","**In summary:**\n","The **R-squared metric** measures how effectively a regression model explains the variability of the dependent variable.\n","A **higher R² value** indicates a **better-fitting model**, meaning the predictions are closer to actual data points.\n","\n","\n"],"metadata":{"id":"QAcOPTbQLjWV"}},{"cell_type":"code","source":["# Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n","# Import necessary libraries\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","# Sample data\n","# X represents the independent variable (e.g., study hours)\n","# Y represents the dependent variable (e.g., exam scores)\n","X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Reshape is needed to make X 2D\n","Y = np.array([2, 4, 5, 4, 5])\n","\n","# Create a Linear Regression model\n","model = LinearRegression()\n","\n","# Fit the model to the data\n","model.fit(X, Y)\n","\n","# Get the slope (coefficient) and intercept\n","slope = model.coef_[0]\n","intercept = model.intercept_\n","\n","# Print the results\n","print(\"Slope (b):\", slope)\n","print(\"Intercept (a):\", intercept)\n","\n","# Optional: Make a prediction for a new value\n","new_X = np.array([[6]])\n","predicted_Y = model.predict(new_X)\n","print(\"Predicted value for X = 6:\", predicted_Y[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wtoKKABQMDse","executionInfo":{"status":"ok","timestamp":1760100946580,"user_tz":-330,"elapsed":2834,"user":{"displayName":"Sneha Pal","userId":"00700588384488618037"}},"outputId":"c726f1cd-b3b8-41ad-b818-6e693fc03ac3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Slope (b): 0.6\n","Intercept (a): 2.2\n","Predicted value for X = 6: 5.8\n"]}]},{"cell_type":"markdown","source":["\n","\n","### **Question 10: How do you interpret the coefficients in a Simple Linear Regression model?**\n","\n","**Answer:**\n","\n","In a **Simple Linear Regression model**, the equation is written as:\n","\n","[\n","Y = a + bX + e\n","]\n","\n","Where:\n","\n","* **Y** = Dependent variable (the value we want to predict)\n","* **X** = Independent variable (the predictor)\n","* **a** = Intercept (constant term)\n","* **b** = Slope (coefficient of X)\n","* **e** = Error term (difference between actual and predicted values)\n","\n","\n","\n","### **1. Intercept (a):**\n","\n","* The **intercept** represents the **predicted value of Y when X = 0**.\n","* It shows where the regression line crosses the Y-axis.\n","* It is the **baseline value** of the dependent variable before any effect of X is applied.\n","\n","**Example:**\n","If the regression equation is\n","[\n","\\text{Sales} = 50 + 10 \\times \\text{Advertising Spend}\n","]\n","Then the **intercept (a = 50)** means — even with ₹0 spent on advertising, the expected sales are ₹50 (perhaps due to regular customers).\n","\n","\n","\n","### **2. Slope (b):**\n","\n","* The **slope** tells us **how much Y changes** for a **one-unit increase in X**.\n","* It indicates both the **direction** and **strength** of the relationship between X and Y.\n","\n","**Interpretation of slope:**\n","\n","* If **b > 0** → Positive relationship (Y increases as X increases).\n","* If **b < 0** → Negative relationship (Y decreases as X increases).\n","* If **b = 0** → No linear relationship between X and Y.\n","\n","**Example:**\n","In the equation\n","[\n","\\text{Sales} = 50 + 10 \\times \\text{Advertising Spend}\n","]\n","the **slope (b = 10)** means that for **every ₹1 increase in advertising**, sales are expected to **increase by ₹10** on average.\n","\n","\n","\n","### **3. Overall Interpretation:**\n","\n","Together, the **intercept** and **slope** describe the **line of best fit** — showing the expected value of Y for any given X.\n","\n","\n","\n"," **In summary:**\n","\n","* **Intercept (a):** Value of Y when X = 0.\n","* **Slope (b):** Change in Y for each unit change in X.\n","* These coefficients help us understand the **relationship strength, direction, and baseline level** in a regression model.\n","\n","\n","\n","\n","  \n"],"metadata":{"id":"cB4ptmelMd58"}}]}